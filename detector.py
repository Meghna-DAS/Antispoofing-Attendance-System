# Code Generated by Sidekick is for learning and experimentation purposes only.
import cv2
import numpy as np
import time
from collections import deque

class AntiSpoofDetector:
    def __init__(self):
        """Initialize enhanced anti-spoofing detector WITHOUT dlib dependency"""
        print("üõ°Ô∏è Initializing Enhanced Anti-Spoof Detector (OpenCV Only)...")
        
        # Initialize OpenCV cascades
        self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
        
        # Basic detection parameters
        self.BLINK_THRESHOLD = 0.6
        self.CONSECUTIVE_FRAMES = 2
        
        # Tracking variables
        self.total_blinks = 0
        self.blink_counter = 0
        self.motion_detected = False
        self.face_detected_frames = 0
        self.total_frames = 0
        
        # VIDEO SPOOFING DETECTION FEATURES
        self.frame_history = deque(maxlen=20)
        self.face_size_history = deque(maxlen=15)
        self.brightness_history = deque(maxlen=12)
        self.texture_history = deque(maxlen=10)
        self.color_history = deque(maxlen=10)
        
        # Video detection flags
        self.video_spoofing_detected = False
        self.spoofing_confidence = 0.0
        
        # Motion detection
        self.previous_frame = None
        self.motion_threshold = 800
        
        # Eye state tracking
        self.previous_eye_count = 2
        self.eye_state_history = []
        
        print("‚úÖ Enhanced Anti-Spoof Detector initialized!")

    def detect_screen_patterns(self, frame):
        """Detect screen/display patterns using OpenCV only"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            
            screen_indicators = 0
            
            # 1. Check brightness distribution
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist_normalized = hist / np.sum(hist)
            max_peak = np.max(hist_normalized)
            
            if max_peak > 0.15:
                screen_indicators += 1
                print("üì∫ Suspicious brightness detected")
            
            # 2. Check blue light excess
            b, g, r = cv2.split(frame)
            blue_mean = np.mean(b)
            total_mean = (np.mean(b) + np.mean(g) + np.mean(r)) / 3
            
            if total_mean > 0 and (blue_mean / total_mean) > 1.3:
                screen_indicators += 1
                print("üíô Excessive blue light detected")
            
            # 3. Check for pixelation
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            edge_variance = np.var(laplacian)
            
            if edge_variance > 500:
                screen_indicators += 1
                print("üî≤ Pixelation detected")
            
            return screen_indicators >= 2
            
        except Exception as e:
            print(f"‚ùå Screen detection error: {e}")
            return False

    def analyze_face_consistency(self, face_rect):
        """Check if face size is too consistent (video indicator)"""
        try:
            if face_rect is not None:
                x, y, w, h = face_rect
                face_area = w * h
                self.face_size_history.append(face_area)
                
                if len(self.face_size_history) >= 8:
                    size_std = np.std(list(self.face_size_history))
                    size_mean = np.mean(list(self.face_size_history))
                    
                    if size_mean > 0:
                        cv_size = size_std / size_mean
                        if cv_size < 0.03:  # Too consistent
                            print("üìè Face size too consistent")
                            return True
            return False
            
        except Exception as e:
            print(f"‚ùå Face consistency error: {e}")
            return False

    def detect_video_spoofing(self, frame, face_rect):
        """Main video spoofing detection"""
        try:
            spoofing_indicators = 0
            
            # Check screen patterns
            if self.detect_screen_patterns(frame):
                spoofing_indicators += 1
            
            # Check face consistency
            if self.analyze_face_consistency(face_rect):
                spoofing_indicators += 1
            
            # Update confidence
            self.spoofing_confidence = spoofing_indicators / 2.0
            
            if self.spoofing_confidence >= 0.5:
                self.video_spoofing_detected = True
                print(f"üö® VIDEO SPOOFING DETECTED! Confidence: {self.spoofing_confidence:.2f}")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Video spoofing detection error: {e}")
            return False

    def detect_eyes_and_blinks(self, frame, face_rect):
        """Enhanced eye detection with spoofing awareness"""
        try:
            x, y, w, h = face_rect
            face_roi = frame[y:y+h, x:x+w]
            face_gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
            
            # Detect eyes
            eyes = self.eye_cascade.detectMultiScale(
                face_gray, 
                scaleFactor=1.1, 
                minNeighbors=5,
                minSize=(15, 15),
                maxSize=(50, 50)
            )
            
            # Filter valid eyes
            valid_eyes = []
            for (ex, ey, ew, eh) in eyes:
                if ey < h * 0.6:  # Upper half only
                    valid_eyes.append((ex, ey, ew, eh))
            
            eye_count = len(valid_eyes)
            
            # Draw eye rectangles
            for (ex, ey, ew, eh) in valid_eyes:
                color = (0, 255, 0) if not self.video_spoofing_detected else (0, 0, 255)
                cv2.rectangle(face_roi, (ex, ey), (ex+ew, ey+eh), color, 2)
            
            # Blink detection
            self.eye_state_history.append(eye_count)
            
            if len(self.eye_state_history) > 10:
                self.eye_state_history.pop(0)
            
            # Detect blink patterns
            if len(self.eye_state_history) >= 5:
                recent_states = self.eye_state_history[-5:]
                
                if (recent_states[0] >= 2 and 
                    min(recent_states[1:3]) <= 1 and 
                    recent_states[-1] >= 2):
                    
                    if self.blink_counter == 0:
                        self.total_blinks += 1
                        self.blink_counter = 3
                        print(f"üëÅÔ∏è BLINK DETECTED! Total: {self.total_blinks}")
            
            if self.blink_counter > 0:
                self.blink_counter -= 1
            
            # Display info
            color = (0, 255, 0) if not self.video_spoofing_detected else (0, 0, 255)
            cv2.putText(frame, f"Eyes: {eye_count}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            cv2.putText(frame, f"Blinks: {self.total_blinks}", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            return eye_count, True
            
        except Exception as e:
            print(f"‚ùå Eye detection error: {e}")
            return 0, False

    def detect_motion(self, frame):
        """Detect motion between frames"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (21, 21), 0)
            
            if self.previous_frame is None:
                self.previous_frame = gray
                return False
            
            frame_delta = cv2.absdiff(self.previous_frame, gray)
            thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]
            thresh = cv2.dilate(thresh, None, iterations=2)
            
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            motion_area = sum(cv2.contourArea(contour) for contour in contours)
            
            self.previous_frame = gray
            motion_detected = motion_area > self.motion_threshold
            
            if motion_detected:
                self.motion_detected = True
                print(f"üîÑ Motion detected: {motion_area:.0f} pixels")
            
            return motion_detected
            
        except Exception as e:
            print(f"‚ùå Motion detection error: {e}")
            return False

    def is_live_person(self):
        """
        Determine if detected person is live (not spoofing)
        Returns True if person appears to be live, False if spoofing detected
        """
        try:
            # Check basic requirements for live person
            min_blinks_required = 2
            min_frames_required = 30
            
            # Calculate success metrics
            face_detection_rate = 0
            if self.total_frames > 0:
                face_detection_rate = self.face_detected_frames / self.total_frames
            
            # Live person criteria
            has_sufficient_blinks = self.total_blinks >= min_blinks_required
            has_sufficient_frames = self.total_frames >= min_frames_required
            has_good_face_detection = face_detection_rate >= 0.7  # 70% face detection rate
            has_motion = self.motion_detected
            no_spoofing_detected = not self.video_spoofing_detected
            
            # Debug information
            print(f"üîç Live Person Check:")
            print(f"   Blinks: {self.total_blinks}/{min_blinks_required} {'‚úÖ' if has_sufficient_blinks else '‚ùå'}")
            print(f"   Frames: {self.total_frames}/{min_frames_required} {'‚úÖ' if has_sufficient_frames else '‚ùå'}")
            print(f"   Face Detection: {face_detection_rate:.2f}/0.70 {'‚úÖ' if has_good_face_detection else '‚ùå'}")
            print(f"   Motion: {'YES' if has_motion else 'NO'} {'‚úÖ' if has_motion else '‚ùå'}")
            print(f"   No Spoofing: {'YES' if no_spoofing_detected else 'NO'} {'‚úÖ' if no_spoofing_detected else '‚ùå'}")
            
            # Final decision
            is_live = (has_sufficient_blinks and 
                      has_sufficient_frames and 
                      has_good_face_detection and 
                      has_motion and 
                      no_spoofing_detected)
            
            if is_live:
                print("‚úÖ RESULT: LIVE PERSON DETECTED")
            else:
                print("‚ùå RESULT: NOT LIVE PERSON (Possible spoofing)")
                
            return is_live
            
        except Exception as e:
            print(f"‚ùå Live person check error: {e}")
            return False

    def analyze_frame(self, frame):
        """Enhanced frame analysis with video spoofing detection"""
        try:
            self.total_frames += 1
            
            # Convert to grayscale for face detection
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Detect faces
            faces = self.face_detector.detectMultiScale(
                gray, 
                scaleFactor=1.1, 
                minNeighbors=5, 
                minSize=(80, 80)
            )
            
            face_detected = len(faces) > 0
            
            if face_detected:
                self.face_detected_frames += 1
                
                # Use largest face
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                x, y, w, h = face
                
                # Check for video spoofing FIRST
                is_spoofing = self.detect_video_spoofing(frame, face)
                
                # Draw face rectangle with appropriate color
                color = (0, 0, 255) if is_spoofing else (255, 0, 0)  # Red if spoofing, blue if normal
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                
                # Add spoofing warning
                if is_spoofing:
                    cv2.putText(frame, "üö® VIDEO SPOOFING DETECTED!", (10, 180), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    cv2.putText(frame, f"Confidence: {self.spoofing_confidence:.2f}", (10, 210), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
                # Detect eyes and blinks
                eye_count, detection_success = self.detect_eyes_and_blinks(frame, face)
            
            # Detect motion
            self.detect_motion(frame)
            
            # Display status
            motion_text = "Motion: YES" if self.motion_detected else "Motion: NO"
            motion_color = (0, 255, 0) if self.motion_detected else (0, 0, 255)
            cv2.putText(frame, motion_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, motion_color, 2)
            
            # Display spoofing status
            if self.video_spoofing_detected:
                cv2.putText(frame, "STATUS: SPOOFING", (10, 120), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(frame, "STATUS: CHECKING", (10, 120), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.putText(frame, f"Frame: {self.total_frames}", (10, 150), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # Return analysis results
            return {
                'face_detected': face_detected,
                'blinks': self.total_blinks,
                'motion_detected': self.motion_detected,
                'frame_count': self.total_frames,
                'video_spoofing': self.video_spoofing_detected,
                'spoofing_confidence': self.spoofing_confidence
            }
            
        except Exception as e:
            print(f"‚ùå Frame analysis error: {e}")
            return {
                'face_detected': False,
                'blinks': 0,
                'motion_detected': False,
                'frame_count': self.total_frames,
                'video_spoofing': False,
                'spoofing_confidence': 0.0
            }

    def reset(self):
        """Reset detector state"""
        print("üîÑ Resetting detector state...")
        self.total_blinks = 0
        self.blink_counter = 0
        self.motion_detected = False
        self.face_detected_frames = 0
        self.total_frames = 0
        self.video_spoofing_detected = False
        self.spoofing_confidence = 0.0
        self.previous_frame = None
        self.eye_state_history = []
        self.frame_history.clear()
        self.face_size_history.clear()
        self.brightness_history.clear()
        self.texture_history.clear()
        self.color_history.clear()
        print("‚úÖ Detector state reset complete!")

    def get_detection_summary(self):
        """Get summary of detection results"""
        face_detection_rate = 0
        if self.total_frames > 0:
            face_detection_rate = self.face_detected_frames / self.total_frames
        
        return {
            'total_frames': self.total_frames,
            'face_detected_frames': self.face_detected_frames,
            'face_detection_rate': face_detection_rate,
            'total_blinks': self.total_blinks,
            'motion_detected': self.motion_detected,
            'video_spoofing_detected': self.video_spoofing_detected,
            'spoofing_confidence': self.spoofing_confidence,
            'is_live_person': self.is_live_person()
        }
